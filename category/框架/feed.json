{
    "version": "https://jsonfeed.org/version/1",
    "title": "菜b的爬虫记录 • All posts by \"框架\" category",
    "description": "",
    "home_page_url": "http://yida506.github.io",
    "items": [
        {
            "id": "http://yida506.github.io/2022/02/02/Framework/",
            "url": "http://yida506.github.io/2022/02/02/Framework/",
            "title": "Framework",
            "date_published": "2022-02-02T15:19:36.000Z",
            "content_html": "<h3 id=\"源码解读\"><a class=\"anchor\" href=\"#源码解读\">#</a> 源码解读</h3>\n<h4 id=\"buffer组件\"><a class=\"anchor\" href=\"#buffer组件\">#</a> BUFFER 组件:</h4>\n<h5 id=\"request_buffer\"><a class=\"anchor\" href=\"#request_buffer\">#</a> REQUEST_BUFFER:</h5>\n<p>定义了 requests 队列和删除队列，用于添加任务 URL 和删除 URL.</p>\n<h5 id=\"item_buffer\"><a class=\"anchor\" href=\"#item_buffer\">#</a> ITEM_BUFFER:</h5>\n<p>将数据添加到数据库中，内置去重等方法。</p>\n<h4 id=\"core组件\"><a class=\"anchor\" href=\"#core组件\">#</a> Core 组件</h4>\n<h5 id=\"baseparser\"><a class=\"anchor\" href=\"#baseparser\">#</a> BaseParser：</h5>\n<p>作为父类，后续继承其中的方法。</p>\n<h5 id=\"collector\"><a class=\"anchor\" href=\"#collector\">#</a> Collector:</h5>\n<p><strong>功能介绍：主要是获取任务，以及分配任务，将 request 和 request 对象存入一个队列中</strong></p>\n<h6 id=\"__-init-__部分\"><a class=\"anchor\" href=\"#__-init-__部分\">#</a> __ init __部分：</h6>\n<p>传入：redis_key</p>\n<p>继承：多线程 threading.Thread 类</p>\n<p>定义：</p>\n<ul>\n<li>\n<p>_thread_stop： boolean</p>\n</li>\n<li>\n<p>_todo_request：定义一个空队列</p>\n</li>\n<li>\n<p>_tab_requests：将 redis_key 传入 requests 表</p>\n</li>\n<li>\n<p>_tab_spider_status：将 redis_key 传入爬取状态表</p>\n</li>\n</ul>\n<p><img data-src=\"Framework/image-20220303211908320.png\" alt=\"image-20220303211908320\"></p>\n<ul>\n<li>_spider_mark：获取本地 ip + 时间，应该是导出日志使用</li>\n<li>_interval ：从任务队列中获取任务到内存队列的间隔</li>\n<li>_request_count: 每次获取的任务数</li>\n<li>_is_collector_task:boolean 判断任务是否被收集</li>\n<li>_first_get_task：boolean 第一次获取任务</li>\n</ul>\n<h6 id=\"run\"><a class=\"anchor\" href=\"#run\">#</a> run:</h6>\n<p>使用 while 循环 (使用 thread_stop 判断)，保证爬虫持续运行。</p>\n<p>运行 report_node_heartbeat ()--&gt;input_data ()，出现异常就打印日志.</p>\n<h6 id=\"stop\"><a class=\"anchor\" href=\"#stop\">#</a> stop:</h6>\n<p>用于将 run 中的 while 循环终止，结束线程</p>\n<h6 id=\"__input_data\"><a class=\"anchor\" href=\"#__input_data\">#</a> __input_data:</h6>\n<ol>\n<li>获取当前时间</li>\n<li>如果任务队列中的任务数量大于任务队列容量，则不向其中添加任务，并返回。</li>\n<li>获取当前任务队列中的任务数量</li>\n<li>获取一定优先级的任务数量 redis 中的方法 (不懂)</li>\n<li>首次任去任务重置 (不懂)</li>\n<li>获取任务</li>\n<li>put_requests 下发任务</li>\n</ol>\n<blockquote>\n<p>不懂 redis 的原理和心跳等</p>\n</blockquote>\n<h6 id=\"__report_node_heartbead\"><a class=\"anchor\" href=\"#__report_node_heartbead\">#</a> __report_node_heartbead：</h6>\n<blockquote>\n<p>redis 相关操作，不懂</p>\n</blockquote>\n<h6 id=\"__delete_dead_node\"><a class=\"anchor\" href=\"#__delete_dead_node\">#</a> __delete_dead_node:</h6>\n<blockquote>\n<p>redis 相关操作，不懂</p>\n</blockquote>\n<h6 id=\"__put_requests\"><a class=\"anchor\" href=\"#__put_requests\">#</a> __put_requests:</h6>\n<p>将任务下发到 request_dict 汇总以获取 request 和 request 对象。</p>\n<p>将获取的字典传入队列。</p>\n<h5 id=\"handle_failed_requests\"><a class=\"anchor\" href=\"#handle_failed_requests\">#</a> HANDLE_FAILED_REQUESTS:</h5>\n<p><strong>主要功能:</strong></p>\n<blockquote>\n<p>redis 相关</p>\n</blockquote>\n<h5 id=\"parser_control\"><a class=\"anchor\" href=\"#parser_control\">#</a> PARSER_CONTROL:</h5>\n<p><strong>主要功能：任务数量统计</strong></p>\n<h6 id=\"init\"><a class=\"anchor\" href=\"#init\">#</a> init:</h6>\n<p>传入：collector,redis_key,request_buffer,item_buffer</p>\n<p>继承：多线程 threading.Thread 类</p>\n<p>定义：</p>\n<ul>\n<li>_parses：空列表</li>\n<li>_collector: 传入</li>\n<li>_redis_key: 传入</li>\n<li>_requeset_buffer: 传入</li>\n<li>_thread_stop:boolean</li>\n<li>_wait_task_time: 0</li>\n</ul>\n<h6 id=\"run-2\"><a class=\"anchor\" href=\"#run-2\">#</a> run:</h6>\n<p>从 collector 中获取任务列表，如果不存在，就等待 1s，同时将 is_show_tip 赋值为 true，用于后续判断。</p>\n<p>将任务列表传入 deal_requests 中。</p>\n<h6 id=\"deal_requests\"><a class=\"anchor\" href=\"#deal_requests\">#</a> deal_requests：</h6>\n<p>获取 request 对象和 request_redis</p>\n<p>解析_parsers 列表，解析中间件，获取 response 结果，对结果进行判断，通过 item_buffer 入口，失败任务检测</p>\n<h5 id=\"scheduler\"><a class=\"anchor\" href=\"#scheduler\">#</a> SCHEDULER：</h5>\n<p>参数:</p>\n<ul>\n<li>redis_key: 爬虫 request 及 item 存放 redis 中的文件夹</li>\n<li>thread_count: 线程数，默认为配置文件中的线程数</li>\n<li>begin_callback: 爬虫开始回调函数</li>\n<li>end_callback: 爬虫结束回调函数</li>\n<li>delete_keys: 爬虫启动时删除的 key，类型：元组 /bool/string。 支持正则</li>\n<li>keep_alive: 爬虫是否常驻，默认否</li>\n<li>auto_start_requests: 爬虫是否自动添加任务</li>\n<li>batch_interval: 抓取时间间隔 默认为 0 天为单位 多次启动时，只有当前时间与第一次抓取结束的时间间隔大于指定的时间间隔时，爬虫才启动</li>\n<li>wait_lock: 下发任务时否等待锁，若不等待锁，可能会存在多进程同时在下发一样的任务，因此分布式环境下请将该值设置 True</li>\n<li>task_table: 任务表， 批次爬虫传递</li>\n</ul>\n<h6 id=\"init-2\"><a class=\"anchor\" href=\"#init-2\">#</a> init:</h6>\n<ul>\n<li>request_buffer: 初始化 RequestBuffer (redis_key) 类</li>\n<li>item_buffer: 初始化 itembuffer (redis_key,task_table)</li>\n<li>_collector: 初始化 Coollector (redis)</li>\n<li>_parsers: 空列表</li>\n<li>_parser_controls: 空列表</li>\n<li>_parser_control_obj:PaserControl</li>\n</ul>\n<h3 id=\"使用教程\"><a class=\"anchor\" href=\"#使用教程\">#</a> 使用教程</h3>\n<p>可采用 download_midware，将 headers 及其他，以字典的形式下发</p>\n<ul>\n<li>\n<p>resoponse.open () 可以看打开的网站是否和浏览器。</p>\n</li>\n<li>\n<p>Requests.feapder (render=True)，表示打开渲染模式，parse_name 跟爬虫文件名 (用于消费任务) 该爬虫需要继承 baseparser，</p>\n</li>\n<li>\n<p>Requests.feapder (params_name=&quot;消费者的类名&quot;), 生产者里面是不需要指定</p>\n</li>\n<li>\n<p>在爬虫集成的时候都使用 baseparser</p>\n<p>Spider(redis_key,delete_key=True)</p>\n<p>delete_key 可以用于重新生成 redis_key</p>\n</li>\n</ul>\n",
            "tags": []
        }
    ]
}