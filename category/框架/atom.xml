<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://yida506.github.io</id>
    <title>菜b的爬虫记录 • Posts by &#34;框架&#34; category</title>
    <link href="http://yida506.github.io" />
    <updated>2021-09-02T15:19:36.000Z</updated>
    <category term="CTF" />
    <category term="YRX" />
    <entry>
        <id>http://yida506.github.io/2021/09/02/Feadper/</id>
        <title>Feapder</title>
        <link rel="alternate" href="http://yida506.github.io/2021/09/02/Feadper/"/>
        <content type="html">&lt;h2 id=&#34;源码解读&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#源码解读&#34;&gt;#&lt;/a&gt; 源码解读&lt;/h2&gt;
&lt;h3 id=&#34;spider&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#spider&#34;&gt;#&lt;/a&gt; Spider&lt;/h3&gt;
&lt;p&gt;分布式爬虫&lt;/p&gt;
&lt;p&gt;Spider 继承 BaseParser, Scheduler&lt;/p&gt;
&lt;h4 id=&#34;运行流程&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#运行流程&#34;&gt;#&lt;/a&gt; 运行流程&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;初始化 Spider (传入 rediskey), 此时会初始化 Spider 中的参数，以及 Scheduler 中的参数，调用多线程中的 start 方法&lt;/li&gt;
&lt;li&gt;在 start 方法中，将当前 Spider 对象存入 self._parsers 中，然后调用 Scheduler 中的_start 方法&lt;/li&gt;
&lt;li&gt;在_start 方法中，调用初始化后的 request_buffer,item_buffer,collector 的 start 方法&lt;/li&gt;
&lt;li&gt;接着根据线程数及进程数，开启多个 parser_control (主要是处理 collector)&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;spider内置方法&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#spider内置方法&#34;&gt;#&lt;/a&gt; Spider 内置方法&lt;/h4&gt;
&lt;h6 id=&#34;方法&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#方法&#34;&gt;#&lt;/a&gt; 方法&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;start_monitor_task 开始监控 常驻：主要涉及 redis 数量任务监控以及下发任务&lt;/li&gt;
&lt;li&gt;distribute_task 分发任务，由于继承了 Scheduler, 所以会初始化 parser 列表&lt;/li&gt;
&lt;li&gt;run 运行线程 然后调用 Scheduler 中的_start () 方法 启动 request_buffer,item_buffer,collector (均继承多线程，用 start () 常驻)&lt;/li&gt;
&lt;li&gt;parser_control&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;组件介绍&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#组件介绍&#34;&gt;#&lt;/a&gt; 组件介绍&lt;/h4&gt;
&lt;h5 id=&#34;scheduler&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#scheduler&#34;&gt;#&lt;/a&gt; Scheduler&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;调度器&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;决定爬虫的执行顺序，以及批次爬虫的调度逻辑&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h6 id=&#34;init&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#init&#34;&gt;#&lt;/a&gt; init&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;self._request_buffer 根据 redis_key 初始化的 request_buffer&lt;/li&gt;
&lt;li&gt;self._item_buffer 根据 redis_key 初始化的 item_buffer&lt;/li&gt;
&lt;li&gt;self._collector 根据 redis_key 初始化的 collector&lt;/li&gt;
&lt;li&gt;self._parsers 数组，用于存放 Spider 对象本身&lt;/li&gt;
&lt;li&gt;self._parser_controls 数组&lt;/li&gt;
&lt;li&gt;self._parser_control_obj  PaserControl 组件 (从 collector 中获取任务 处理 request)&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;request_buffer&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#request_buffer&#34;&gt;#&lt;/a&gt; request_buffer&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;init 初始化 requests 队列，del_requests 队列&lt;/li&gt;
&lt;li&gt;run: 只要未结束，就不断的往 redis 中添加任务&lt;/li&gt;
&lt;li&gt;__add_request_to_db: 将内存队列的中的任务添加至 redis 中&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;item_buffer&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#item_buffer&#34;&gt;#&lt;/a&gt; item_buffer&lt;/h5&gt;
&lt;h5 id=&#34;collector&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#collector&#34;&gt;#&lt;/a&gt; collector&lt;/h5&gt;
&lt;h5 id=&#34;request&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#request&#34;&gt;#&lt;/a&gt; Request&lt;/h5&gt;
&lt;p&gt;封装了 request&lt;br&gt;
 缓存配置 (用于 debug 爬虫)&lt;/p&gt;
&lt;h5 id=&#34;pasercontrol&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#pasercontrol&#34;&gt;#&lt;/a&gt; PaserControl&lt;/h5&gt;
&lt;h6 id=&#34;run&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#run&#34;&gt;#&lt;/a&gt; run&lt;/h6&gt;
&lt;p&gt;从内存队列中取 request, 对其数量进行判断，然后处理中间件，获取返回后的结果&lt;/p&gt;
</content>
        <updated>2021-09-02T15:19:36.000Z</updated>
    </entry>
</feed>
