{
    "version": "https://jsonfeed.org/version/1",
    "title": "菜b的爬虫记录 • All posts by \"机器学习\" category",
    "description": "",
    "home_page_url": "http://yida506.github.io",
    "items": [
        {
            "id": "http://yida506.github.io/2022/06/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/",
            "url": "http://yida506.github.io/2022/06/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/",
            "title": "数据挖掘介绍",
            "date_published": "2022-06-01T12:34:27.000Z",
            "content_html": "<h4 id=\"概述\"><a class=\"anchor\" href=\"#概述\">#</a> 概述</h4>\n<h3 id=\"1数据挖掘基本任务\"><a class=\"anchor\" href=\"#1数据挖掘基本任务\">#</a> 1. 数据挖掘基本任务</h3>\n<p>利用分类与预测、聚类分析、关联分析、时序分析、偏差分析、智能推荐等方法，帮助企业提取数据中蕴含的商业价值，提高企业的核心竞争力。</p>\n<h3 id=\"2数据挖掘的建模过程\"><a class=\"anchor\" href=\"#2数据挖掘的建模过程\">#</a> 2. 数据挖掘的建模过程</h3>\n<ul>\n<li>目标定义</li>\n<li>数据采集</li>\n<li>数据整理</li>\n<li>构建模型</li>\n<li>模型评估</li>\n<li>模型上线</li>\n</ul>\n<h4 id=\"21定义挖掘目标\"><a class=\"anchor\" href=\"#21定义挖掘目标\">#</a> 2.1 定义挖掘目标</h4>\n<p>针对不同的数据挖掘应用需求，我们需要了解目标领域的相关知识，熟悉背景知识，弄清客户需求。</p>\n<p>通常来讲，定义目标可以细致的分为任务理解、指标确立这两个步骤。</p>\n<p>这里以电商平台为例来阐述：</p>\n<p>对于任务理解来讲，我们通常希望采取一定的策略使得商家的利润增加、同时也使得消费者满意度增加，达到双赢的效果。</p>\n<p>以消费者的角度来看，我们在购买商品的时候，往往会因为商品数量过多，无法对所有的商品有所了解，因此，如何使得消费者能快速的找到满意的商品对提高消费者的满意度有很高的价值。</p>\n<p>对于商家来讲，不同的消费者往往在购买时往往会有不同的消费习惯，例如，经常购买的往往会一次性买很多，而不经常买的往往会选择一部分先进行观望，这样如果能把这些用户分开，对不同的用户采取不同的营销策略，也可以进一步实现提高用户满意度、利润增加；同时，在不同的季节，消费者购买所关注点也是不同的，若能将其区分开来，同样也可解决商家货供给不足、消费者需求无法很好的满足的问题。</p>\n<p>在经过初步的任务理解后，已经对要做的事有了一个大致的了解，接着就需要对其建立详细的指标，由于指标的建立往往需要实际的业务经验，这里暂时不过多描述。</p>\n<h4 id=\"22-数据取样\"><a class=\"anchor\" href=\"#22-数据取样\">#</a> 2.2 数据取样</h4>\n<p>在明确了数据挖掘的目标后，接下来就是需要获取数据，我们在分析时，不可能拿全部数据进行分析，因为这样耗时耗力，通常采取取样方法，获取样本子集。在取样的同时，还需要特别关注数据的质量，若是数据有误，那么根据数据进行后续操作往往会造成误导，从而得到错误的结论，所以在取样是要注重数据的完整性和有效性。</p>\n<h5 id=\"衡量数据质量指标齐全-数据正常数据不正常往往是服务器等出现问题导致的\"><a class=\"anchor\" href=\"#衡量数据质量指标齐全-数据正常数据不正常往往是服务器等出现问题导致的\">#</a> 衡量数据质量：指标齐全、数据正常 (数据不正常往往是服务器等出现问题导致的)</h5>\n<p>抽样方法采用统计学的抽样方法即可。</p>\n<h4 id=\"23-数据探索\"><a class=\"anchor\" href=\"#23-数据探索\">#</a> 2.3 数据探索</h4>\n<p>在拿到数据后，我们往往会想找到其中的规律，比如各个数据之间有没有什么关联等等，这些都是需要探索的问题。</p>\n",
            "tags": []
        },
        {
            "id": "http://yida506.github.io/2022/03/04/HMM/",
            "url": "http://yida506.github.io/2022/03/04/HMM/",
            "title": "HMM",
            "date_published": "2022-03-04T12:50:02.000Z",
            "content_html": "<h4 id=\"mm\"><a class=\"anchor\" href=\"#mm\">#</a> MM</h4>\n<h6 id=\"markov-model\"><a class=\"anchor\" href=\"#markov-model\">#</a> markov model：</h6>\n<p>马尔可夫模型，指的是在给定当前知识的情况下，过去对于预测未来是无关的，诶个状态的转移，只依赖之前的 n 个状态，被称为是一个 n 阶模型。</p>\n<p><img data-src=\"http://pic.ddddhm.cn/HMM/image-20220305130113281.png\" alt=\"image-20220305130113281\"></p>\n<h6 id=\"转移矩阵\"><a class=\"anchor\" href=\"#转移矩阵\">#</a> 转移矩阵：</h6>\n<p>指的是从一个状态转移到另一个状态的概率，整体上为一个 n*n 的矩阵</p>\n<h4 id=\"hmm\"><a class=\"anchor\" href=\"#hmm\">#</a> HMM</h4>\n<p>用来描述 含有隐含未知参数的马尔可夫过程。对于投色子来讲，假如有三种色子，分别包含 6 8 10 个面，那么每个色子表现出 1 的概率是不同的，同时，我们还知道色子丢出来的结果到底是几，那么我们就可以用这个结果去反推出对应的值是由哪个色子投出来的。</p>\n<h6 id=\"hidden-state\"><a class=\"anchor\" href=\"#hidden-state\">#</a> HIDDEN STATE:</h6>\n<p>隐藏状态集合</p>\n<h6 id=\"observations-state\"><a class=\"anchor\" href=\"#observations-state\">#</a> Observations state:</h6>\n<p>观测状态集合</p>\n<h6 id=\"start-probability\"><a class=\"anchor\" href=\"#start-probability\">#</a> Start Probability:</h6>\n<p>隐藏状态初始化的概率值</p>\n<h6 id=\"hidden-transition_probability\"><a class=\"anchor\" href=\"#hidden-transition_probability\">#</a> Hidden Transition_Probability:</h6>\n<p>隐藏状态概率转移矩阵</p>\n<h6 id=\"hidden-to-observations-probability\"><a class=\"anchor\" href=\"#hidden-to-observations-probability\">#</a> Hidden to Observations Probability:</h6>\n<p>隐藏状态到观测状态概率集合</p>\n<h5 id=\"viterb算法\"><a class=\"anchor\" href=\"#viterb算法\">#</a> Viterb 算法</h5>\n<p>本质上是动态规划，假设初始状态有 n 种，观测序列的长度为 m，那么总共的路径数就为 m 的 n 次方，要想从中找到最优路径往往是不显示的，但是，对于一段长度为 x 路径来说，要是该路径是最优的，那么其长度为 x-1 的子路径也一定是最优的，那么问题就变为了，根据每一条路径，在其基础上，找到其距下个节点的最优路径即可，这样问题就缩小为了 m*n 个，极大降低了复杂度。</p>\n<h6 id=\"demo以一个看病为例\"><a class=\"anchor\" href=\"#demo以一个看病为例\">#</a> DEMO (以一个看病为例)</h6>\n<p>首先定义了隐藏状态：健康、生病</p>\n<p>观测序列：正常，冷，发烧 (这里指代我们看到的情况)</p>\n<p>初始概率：健康：0.6 生病：0.4</p>\n<p>隐藏状态概率转移矩阵：健康到健康 0.7 健康到生病 0.3 生病到健康 0.4 生病到生病 0.6’</p>\n<p>隐藏状态到观测状态概率集合:</p>\n<figure class=\"highlight json\"><figcaption data-lang=\"JSON\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token property\">\"Healthy\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">&#123;</span><span class=\"token property\">\"normal\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"cold\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.4</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"dizzy\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre> <span class=\"token property\">\"Fever\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">&#123;</span><span class=\"token property\">\"normal\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"cold\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> <span class=\"token property\">\"dizzy\"</span><span class=\"token operator\">:</span> <span class=\"token number\">0.6</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr></table></figure><p>我们要根据观测序列推断出其真实情况，在这里每一条路径都是由上一时刻的状态 X 隐藏状态转移概率矩阵 X 隐藏状态到观测状态概率集合 (这里要针对每一个隐藏状态，因为需要对这个隐藏状态进行解码).</p>\n<p><img data-src=\"http://pic.ddddhm.cn/HMM/image-20220305170041105.png\" alt=\"image-20220305170041105\"></p>\n<p>python 实现：</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>Hidden_states <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"Healthy\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Fever\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 隐状态集合</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>Observations_states <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"normal\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"cold\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"dizzy\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 观测状态集合</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>Start_probability <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token string\">\"Healthy\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.6</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token string\">\"Fever\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.4</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">&#125;</span>  <span class=\"token comment\"># 表示病人第一次到访时医生认为其所处的 HMM 状态，他唯一知道的是病人倾向于是健康的（可以理解为这是基于一个对大众身体信息的了解得出的初始状态）</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token number\">2</span><span class=\"token operator\">*</span><span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>Hidden_transition_probability <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>  <span class=\"token comment\"># 隐马尔可夫链中身体状态的状态转移概率，我们能够看到，当天健康的人，第二天有 30% 的概率会发烧</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token string\">\"Healthy\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"Healthy\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.7</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Fever\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.3</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token string\">\"Fever\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"Healthy\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.4</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Fever\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.6</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token number\">3</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>Hidden_observations_probability <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token punctuation\">&#123;</span>  <span class=\"token comment\"># 原来叫 emission_probability。这里表示病人每天的感觉的可能性。即，如果他是一个健康人，有 50% 的可能会感觉正常，40% 觉得冷，10% 觉得头晕</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        <span class=\"token string\">\"Healthy\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"normal\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"cold\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.4</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"dizzy\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        <span class=\"token string\">\"Fever\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">&#123;</span><span class=\"token string\">\"normal\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"cold\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.3</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"dizzy\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.6</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre></pre></td></tr><tr><td data-num=\"22\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">viterbi</span><span class=\"token punctuation\">(</span>obs<span class=\"token punctuation\">,</span> states<span class=\"token punctuation\">,</span> start_p<span class=\"token punctuation\">,</span> trans_p<span class=\"token punctuation\">,</span> h2o_p<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># Viterbi 算法</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    V <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    path <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    <span class=\"token comment\"># Initialize base cases (t == 0)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    <span class=\"token comment\"># </span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>    <span class=\"token keyword\">for</span> y <span class=\"token keyword\">in</span> states<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>        V<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> start_p<span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> h2o_p<span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>obs<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> </pre></td></tr><tr><td data-num=\"30\"></td><td><pre>        <span class=\"token comment\"># 初始状态，由 start 的概率，对应乘上发射概率，即由隐状态到观测状态的可能性</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        path<span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span> <span class=\"token comment\"># 记录下相应的路径</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>    <span class=\"token comment\"># Run Viterbi for t > 0，每天都要更新计算一遍</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>    <span class=\"token keyword\">for</span> t <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>obs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>        V<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        newpath <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        <span class=\"token keyword\">for</span> y <span class=\"token keyword\">in</span> states<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>            <span class=\"token comment\"># 对于每个状态，计算其由前一天的各个状态，到达今天的 y 的概率大小，与 y0 自身相比较，取最大值</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>            <span class=\"token comment\"># 前一天到达今天的每个状态对应的路径大小都计算了，取最大值。作为 V [t][y] 的值，并更新路径</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>            <span class=\"token comment\"># print('V[t-1]:',V[t-1],'trans_p:',trans_p,'h2o_p[y]:',h2o_p[y],[V[t-1][y0] * trans_p[y0][y] * h2o_p[y][obs[t]] for y0 in states])</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>            <span class=\"token punctuation\">(</span>prob<span class=\"token punctuation\">,</span> state<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>V<span class=\"token punctuation\">[</span>t<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>y0<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> trans_p<span class=\"token punctuation\">[</span>y0<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> h2o_p<span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>obs<span class=\"token punctuation\">[</span>t<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y0<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> y0 <span class=\"token keyword\">in</span> states<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>V<span class=\"token punctuation\">[</span>t<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>            V<span class=\"token punctuation\">[</span>t<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> prob</pre></td></tr><tr><td data-num=\"45\"></td><td><pre>            newpath<span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> path<span class=\"token punctuation\">[</span>state<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>        <span class=\"token comment\"># Don't need to remember the old paths</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>        path <span class=\"token operator\">=</span> newpath</pre></td></tr><tr><td data-num=\"49\"></td><td><pre>        <span class=\"token comment\"># print(path)</span></pre></td></tr><tr><td data-num=\"50\"></td><td><pre>    <span class=\"token comment\"># print_dptable(V)</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre>    <span class=\"token comment\"># 最后一天</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>    <span class=\"token punctuation\">(</span>prob<span class=\"token punctuation\">,</span> state<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>V<span class=\"token punctuation\">[</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>obs<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> y <span class=\"token keyword\">in</span> states<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">(</span>prob<span class=\"token punctuation\">,</span> path<span class=\"token punctuation\">[</span>state<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"55\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">example</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>    <span class=\"token keyword\">return</span> viterbi<span class=\"token punctuation\">(</span>Observations_states<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>                   Hidden_states<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>                   Start_probability<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"59\"></td><td><pre>                   Hidden_transition_probability<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>                   Hidden_observations_probability<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>example<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><h5 id=\"实际案例\"><a class=\"anchor\" href=\"#实际案例\">#</a> 实际案例</h5>\n<p>已知：</p>\n<ul>\n<li>观测序列 (指历年主题比重)</li>\n<li>状态转移矩阵：共现词矩阵 (需要进行一个归一化)</li>\n</ul>\n<p>目的：使用 Baum-Welch 算法，根据 12-21 年的比重，预测 22-25 年的比重</p>\n",
            "tags": []
        },
        {
            "id": "http://yida506.github.io/2022/02/27/%E5%85%B3%E8%81%94%E6%8C%96%E6%8E%98/",
            "url": "http://yida506.github.io/2022/02/27/%E5%85%B3%E8%81%94%E6%8C%96%E6%8E%98/",
            "title": "关联挖掘",
            "date_published": "2022-02-27T08:14:42.000Z",
            "content_html": "<h4 id=\"关联挖掘\"><a class=\"anchor\" href=\"#关联挖掘\">#</a> 关联挖掘</h4>\n<h5 id=\"基本概念\"><a class=\"anchor\" href=\"#基本概念\">#</a> 基本概念</h5>\n<p>频繁项集：n 项的集合。</p>\n<p>支持度：代表 A、B 同时出现的概率，如果概率小，那么说明 A 与 B 的关系不大，如果 A、B 总是同时出现，那么说明他们是相关的。</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>s</mi><mi>u</mi><mi>p</mi><mi>p</mi><mi>o</mi><mi>r</mi><mi>t</mi><mo>=</mo><mi>P</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mi>U</mi><mi>B</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">support = P(AUB)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">U</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>置信度：包含 A 的数据集中包含 B 的百分比。</p>\n<h5 id=\"apriori算法\"><a class=\"anchor\" href=\"#apriori算法\">#</a> Apriori 算法</h5>\n<p>使用候选项集找频繁项集</p>\n<p>核心思想，只要一个项集是非频繁的，那么包含他的项集就都是非频繁的。</p>\n<h5 id=\"算法实现\"><a class=\"anchor\" href=\"#算法实现\">#</a> 算法实现</h5>\n<p>关联矩阵转布尔矩阵</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>data <span class=\"token operator\">=</span> final_data<span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">map_func</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">if</span> x <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token keyword\">return</span> <span class=\"token boolean\">True</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> data<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    data<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span>map_func<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>计算关联规则</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">from</span> mlxtend<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> TransactionEncoder</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> mlxtend<span class=\"token punctuation\">.</span>frequent_patterns <span class=\"token keyword\">import</span> apriori</pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token comment\">#利用 Apriori 找出频繁项集</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>freq <span class=\"token operator\">=</span> apriori<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> min_support<span class=\"token operator\">=</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> use_colnames<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\">#导入关联规则包</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token keyword\">from</span> mlxtend<span class=\"token punctuation\">.</span>frequent_patterns <span class=\"token keyword\">import</span> association_rules</pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\">#计算关联规则</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>result <span class=\"token operator\">=</span> association_rules<span class=\"token punctuation\">(</span>freq<span class=\"token punctuation\">,</span> metric<span class=\"token operator\">=</span><span class=\"token string\">\"confidence\"</span><span class=\"token punctuation\">,</span> min_threshold<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>这里采用最小支持度为 0.1，最小置信度为 0.8</p>\n<p><img data-src=\"http://pic.ddddhm.cn/%E5%85%B3%E8%81%94%E6%8C%96%E6%8E%98/image-20220227175750485.png\" alt=\"image-20220227175750485\"></p>\n<p>会得到如下 51 项关联规则，其中 support 代表支持度，confidence 代表提升度。</p>\n<p>画图：</p>\n<p><img data-src=\"http://pic.ddddhm.cn/%E5%85%B3%E8%81%94%E6%8C%96%E6%8E%98/image-20220227175825809.png\" alt=\"image-20220227175825809\"></p>\n",
            "tags": []
        },
        {
            "id": "http://yida506.github.io/2022/02/26/TF-IDF/",
            "url": "http://yida506.github.io/2022/02/26/TF-IDF/",
            "title": "TF-IDF",
            "date_published": "2022-02-26T12:06:25.000Z",
            "content_html": "<h4 id=\"算法简介\"><a class=\"anchor\" href=\"#算法简介\">#</a> 算法简介:</h4>\n<h5 id=\"tf\"><a class=\"anchor\" href=\"#tf\">#</a> TF:</h5>\n<p>TF 算法，全称 Term frequency，翻译过来就是词频，顾名思义，就是词的频率：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>某词语的词频</mtext><mo>=</mo><mfrac><mtext>该词语在一篇文章所出现的次数</mtext><mtext>该篇文章包含的词语数</mtext></mfrac></mrow><annotation encoding=\"application/x-tex\">某词语的词频 = \\frac{该词语在一篇文章所出现的次数}{该篇文章包含的词语数}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">某</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">语</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">频</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.04633em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.36033em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord cjk_fallback\">该</span><span class=\"mord cjk_fallback\">篇</span><span class=\"mord cjk_fallback\">文</span><span class=\"mord cjk_fallback\">章</span><span class=\"mord cjk_fallback\">包</span><span class=\"mord cjk_fallback\">含</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">语</span><span class=\"mord cjk_fallback\">数</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord cjk_fallback\">该</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">语</span><span class=\"mord cjk_fallback\">在</span><span class=\"mord cjk_fallback\">一</span><span class=\"mord cjk_fallback\">篇</span><span class=\"mord cjk_fallback\">文</span><span class=\"mord cjk_fallback\">章</span><span class=\"mord cjk_fallback\">所</span><span class=\"mord cjk_fallback\">出</span><span class=\"mord cjk_fallback\">现</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">次</span><span class=\"mord cjk_fallback\">数</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>通常来讲，我们认为一个词出现的次数越多，那么该词语就越重要，但是，由于语言的特性，文章中包含许许多多停用词，虚词等无实际意义的词语，那么我们在对中文文本进行处理的时候，首先要对其进行一个预处理操作，去掉文章中的停用词等，以消除无实际意义的词产生的影响。</p>\n<p>但是，由于一词多意及同义词的现象，单纯的词频统计往往在计算关键词的时候，出现一定的偏差，导致所得结果与实际情况差别较大。</p>\n<blockquote>\n<p>词频指代的是一篇文章</p>\n</blockquote>\n<h5 id=\"idf\"><a class=\"anchor\" href=\"#idf\">#</a> IDF:</h5>\n<p>IDF 算法，全称 Inverse Document Frequency，意译过来就是逆文档频率。</p>\n<p><strong>核心思想:</strong></p>\n<p>一个词语在文档中出现的次数越少，那么逆文档频率越大，即区分类别的能力越强，可以认为是关键词。</p>\n<p><strong>逆文档解释 (个人理解)：</strong></p>\n<p>​\t\t记总共有 m 个文档，有 n 个文档中包含了某一个词语，那么对于该词语的文档出现概率为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>某词语的文档频率</mtext><mo>=</mo><mfrac><mrow><mtext>出现该词语的</mtext><mi>n</mi><mtext>篇文档</mtext></mrow><mrow><mi>m</mi><mtext>篇文档</mtext></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">某词语的文档频率 = \\frac{出现该词语的n篇文档}{m篇文档}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">某</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">语</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">文</span><span class=\"mord cjk_fallback\">档</span><span class=\"mord cjk_fallback\">频</span><span class=\"mord cjk_fallback\">率</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.04633em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.36033em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">m</span><span class=\"mord cjk_fallback\">篇</span><span class=\"mord cjk_fallback\">文</span><span class=\"mord cjk_fallback\">档</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord cjk_fallback\">出</span><span class=\"mord cjk_fallback\">现</span><span class=\"mord cjk_fallback\">该</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">语</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord mathnormal\">n</span><span class=\"mord cjk_fallback\">篇</span><span class=\"mord cjk_fallback\">文</span><span class=\"mord cjk_fallback\">档</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>假设一个词只在 100 篇文档中出现，但是由于文档数量过大 (例如 10000)，那么该词语的文档频率就会非常的小 (1%)，和 0 基本上没任何区别，也就是说，这个词和没出现的词没明显的差异，并不能做到对文档有很好的区分作用。</p>\n<p>在此基础上，若我们取文档频率的倒数 (这里称为逆频率)，那么上述提到的值就为 100，这样一来，就可以很好的消除未出现词的影响，以及对关键词有一个很好的区分作用。</p>\n<p>但是，这样一来还是有问题，直接取倒数的话，得到的数据过于离散，在上述例子中，逆频率最少 (词只出现一次为 10000) 与最多 (词篇篇都出现 1) 的量级就会过大，在数学上，常用对数的方法，以消除量级过大的影响。</p>\n<p>因此最终逆文档的公式：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>某词语逆文档频率</mtext><mo>=</mo><mfrac><mrow><mi>m</mi><mtext>篇文档</mtext></mrow><mrow><mtext>出现该词语的文档数</mtext><mo>+</mo><mn>1</mn></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">某词语逆文档频率 = \\frac{m篇文档}{出现该词语的文档数+1}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">某</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">语</span><span class=\"mord cjk_fallback\">逆</span><span class=\"mord cjk_fallback\">文</span><span class=\"mord cjk_fallback\">档</span><span class=\"mord cjk_fallback\">频</span><span class=\"mord cjk_fallback\">率</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.1296600000000003em;vertical-align:-0.7693300000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.36033em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord cjk_fallback\">出</span><span class=\"mord cjk_fallback\">现</span><span class=\"mord cjk_fallback\">该</span><span class=\"mord cjk_fallback\">词</span><span class=\"mord cjk_fallback\">语</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord cjk_fallback\">文</span><span class=\"mord cjk_fallback\">档</span><span class=\"mord cjk_fallback\">数</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\">1</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">m</span><span class=\"mord cjk_fallback\">篇</span><span class=\"mord cjk_fallback\">文</span><span class=\"mord cjk_fallback\">档</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693300000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<blockquote>\n<p>补充：这里 + 1 的主要目的是为了消除未出现的词的影响 (使逆文档频率无穷大).</p>\n</blockquote>\n<h5 id=\"tf-idf\"><a class=\"anchor\" href=\"#tf-idf\">#</a> TF-IDF</h5>\n<p>词频 - 逆文档频率，本质上就是 TF 和 IDF 的乘积，TF 的本质是要获取当前文章的高频词语，而 IDF 是计算该词语在文档集合中的重要程度，对于一个词，只在一篇文章中出现多次，那么该词就会有很高的 TF 以及 IDF，那么我们就认为这个词就是关键词.</p>\n<blockquote>\n<p>TF-IDF 本质上是综合了 TF 和 IDF 的特性，对关键词加以区分的算法.</p>\n</blockquote>\n<h4 id=\"简单案例\"><a class=\"anchor\" href=\"#简单案例\">#</a> 简单案例</h4>\n<p>这里采用 Python 的 Sklearn 包为例 (取自网上 Demo).</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#导入特征提取包，第一个用于计数，第二个用于计算词频</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>feature_extraction<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> CountVectorizer</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>feature_extraction<span class=\"token punctuation\">.</span>text <span class=\"token keyword\">import</span> TfidfTransformer</pre></td></tr><tr><td data-num=\"4\"></td><td><pre> </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>x_train <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'TF-IDF 主要 思想 是'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>           <span class=\"token string\">'算法 一个 重要 特点 可以 脱离 语料库 背景'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>           <span class=\"token string\">'如果 一个 网页 被 很多 其他 网页 链接 说明 网页 重要'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>x_test<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'原始 文本 进行 标记'</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token string\">'主要 思想'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre> </pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token comment\">#该类会将文本中的词语转换为词频矩阵，矩阵元素 a [i][j] 表示 j 词在 i 类文本下的词频</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>vectorizer <span class=\"token operator\">=</span> CountVectorizer<span class=\"token punctuation\">(</span>max_features<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\">#该类会统计每个词语的 tf-idf 权值</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>tf_idf_transformer <span class=\"token operator\">=</span> TfidfTransformer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token comment\">#将文本转为词频矩阵并计算 tf-idf</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>tf_idf <span class=\"token operator\">=</span> tf_idf_transformer<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>vectorizer<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>x_train<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token comment\">#将 tf-idf 矩阵抽取出来，元素 a [i][j] 表示 j 词在 i 类文本中的 tf-idf 权重</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>x_train_weight <span class=\"token operator\">=</span> tf_idf<span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre> </pre></td></tr><tr><td data-num=\"20\"></td><td><pre><span class=\"token comment\">#对测试集进行 tf-idf 权重计算</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>tf_idf <span class=\"token operator\">=</span> tf_idf_transformer<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>vectorizer<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>x_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>x_test_weight <span class=\"token operator\">=</span> tf_idf<span class=\"token punctuation\">.</span>toarray<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 测试集 TF-IDF 权重矩阵</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token comment\"># 获取关键词集</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_keywords</span><span class=\"token punctuation\">(</span>matrixArray<span class=\"token punctuation\">,</span> keywordsArray<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">[</span>keywordsArray<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> index <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>matrixArray<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> matrixArray<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token operator\">></span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> </pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'输出x_train文本向量：'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_train_weight<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'输出x_test文本向量：'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_test_weight<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x_test_weight<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'测试集第</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>i<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">个文本的关键词是'</span></span><span class=\"token punctuation\">,</span>get_keywords<span class=\"token punctuation\">(</span>x_test_weight<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> vectorizer<span class=\"token punctuation\">.</span>get_feature_names_out<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>这里 x_train 代表我们采用了三个文本，x_test 用于测试.</p>\n<ol>\n<li>首先我们载入包和训练集和测试集</li>\n<li>接着采用计数类，将词语转化为词频矩阵。然后初始化一个用于计算 tf-idf 的类</li>\n<li>将训练集导入其中进行训练。最后输出测试集中的关键词.</li>\n</ol>\n<p><img data-src=\"http://pic.ddddhm.cn/TF-IDF/image-20220226224241971.png\" alt=\"image-20220226224241971\"></p>\n<h4 id=\"项目实战\"><a class=\"anchor\" href=\"#项目实战\">#</a> 项目实战</h4>\n<h5 id=\"项目背景\"><a class=\"anchor\" href=\"#项目背景\">#</a> 项目背景:</h5>\n<p>采集 http://www.safehoo.com/Case/Case/Collapse 网站的数据，收集每段事故的标题，事故概况，事故原因，采取 TFIDF 算法计算出关键词.</p>\n<h5 id=\"数据采集\"><a class=\"anchor\" href=\"#数据采集\">#</a> 数据采集</h5>\n<h6 id=\"网址分析\"><a class=\"anchor\" href=\"#网址分析\">#</a> 网址分析:</h6>\n<p>首先进入网址发现总共包含 668 条数据要采集，每页包含 30 条数据，通过翻页发现，该网站是由页码来控制网站展示的内容，在这里<span class=\"exturl\" data-url=\"aHR0cDovL3d3dy5zYWZlaG9vLmNvbS9DYXNlL0Nhc2UvQ29sbGFwc2UvTGlzdF8yMy5zaHRtbA==\">坍塌事故 - 案例分析 - 安全管理网 (safehoo.com)</span> 表示的是携带最新数据的页码，其网址中包含的页码为 23, 进一步分析，发现其尾页的页码为 1. 同时，页面是通过 a 标签的 href 链接进行跳转到事故的详情页的，在详情页中数据都是保存在类名为 c_content_text 的 div 标签中。针对如上网站，设计如下爬取思路:</p>\n<ol>\n<li>对携带页面的页面进行请求，解析网页，获取指向详情页的链接，将其保存在 EXCEL 中</li>\n<li>对第一步爬取的详情页链接发起请求，对网页进行解析，将解析的结果以 EXCEL 保存.</li>\n</ol>\n<h6 id=\"爬虫程序撰写\"><a class=\"anchor\" href=\"#爬虫程序撰写\">#</a> 爬虫程序撰写</h6>\n<p>这里使用 Python 撰写爬虫.</p>\n<p>模块介绍:requests+re+etree+pandas+tqdm</p>\n<ul>\n<li><strong>requests:</strong> 爬虫模块，主要用于向网站发起请求，获取网址的 HTML 文本</li>\n<li>**re:** 正则表达式模块，用于文本进行处理等操作</li>\n<li>**etree:** 将 HTML 文本转化为解析树的形式，以用于对网页的解析</li>\n<li>**pandas:** 数据处理模块，可将数据存入 EXCEL</li>\n<li><strong>tqdm</strong>: 进度条</li>\n</ul>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 详情页爬取</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token comment\"># requests 爬取网页</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> requests</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 解析网页 </span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">from</span> lxml <span class=\"token keyword\">import</span> etree</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># 正则表达式</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">import</span> re</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># 将 dataframe (数据框) 导出成 excel</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd</pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># 将代码执行过程以进度条展示</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token keyword\">from</span> tqdm <span class=\"token keyword\">import</span> tqdm</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>tempdict <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\">#     存储的标题</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token string\">'title'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token comment\">#     没用</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token string\">'dtype'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token comment\">#     目标网址链接</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token string\">'urlhref'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>headers <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    <span class=\"token string\">'User-Agent'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36 Edg/98.0.1108.56'</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token comment\">#对网址发起请求</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> tqdm<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">23</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    baseurl <span class=\"token operator\">=</span> <span class=\"token string\">'http://www.safehoo.com'</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>    url <span class=\"token operator\">=</span> baseurl <span class=\"token operator\">+</span> <span class=\"token string-interpolation\"><span class=\"token string\">f'/Case/Case/Collapse/List_</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>i<span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">.shtml'</span></span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    <span class=\"token comment\">#网址先包含了对浏览器的检测，要加入 headers</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>    res <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">,</span> headers<span class=\"token operator\">=</span>headers<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    <span class=\"token comment\">#转化格式，防止乱码出现</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>    res<span class=\"token punctuation\">.</span>encoding <span class=\"token operator\">=</span> <span class=\"token string\">'utf-8'</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>    html <span class=\"token operator\">=</span> etree<span class=\"token punctuation\">.</span>HTML<span class=\"token punctuation\">(</span>res<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>    a <span class=\"token operator\">=</span> html<span class=\"token punctuation\">.</span>xpath<span class=\"token punctuation\">(</span><span class=\"token string\">'//div[@class=\"childclass_content\"]/li'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> a<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        <span class=\"token comment\"># 标题，进行异常检测</span></pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"38\"></td><td><pre>            tempdict<span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">.</span>xpath<span class=\"token punctuation\">(</span><span class=\"token string\">'./a/text()'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        <span class=\"token keyword\">except</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>            tempdict<span class=\"token punctuation\">[</span><span class=\"token string\">'title'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">.</span>xpath<span class=\"token punctuation\">(</span><span class=\"token string\">'./a/font/text()'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre>        <span class=\"token comment\"># 类型</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>        tempdict<span class=\"token punctuation\">[</span><span class=\"token string\">'dtype'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">,</span>re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">'[A-Za-z0-9\\!\\%\\[\\]\\,\\。]'</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">,</span>i<span class=\"token punctuation\">.</span>xpath<span class=\"token punctuation\">(</span><span class=\"token string\">'./text()'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>        <span class=\"token comment\"># 地址</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>        tempdict<span class=\"token punctuation\">[</span><span class=\"token string\">'urlhref'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>baseurl<span class=\"token operator\">+</span>i<span class=\"token punctuation\">.</span>xpath<span class=\"token punctuation\">(</span><span class=\"token string\">'./a/@href'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"46\"></td><td><pre><span class=\"token comment\">#将数据转化为数据框格式</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>tempdict<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre><span class=\"token comment\">#将数据保存到 excel 里面</span></pre></td></tr><tr><td data-num=\"49\"></td><td><pre>df<span class=\"token punctuation\">.</span>to_excel<span class=\"token punctuation\">(</span><span class=\"token string\">'output.xlsx'</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># 内容爬取</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> re</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">import</span> requests</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">from</span> tqdm <span class=\"token keyword\">import</span> tqdm</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token keyword\">from</span> lxml <span class=\"token keyword\">import</span> etree</pre></td></tr><tr><td data-num=\"7\"></td><td><pre></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_excel<span class=\"token punctuation\">(</span><span class=\"token string\">'output.xlsx'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>url <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'urlhref'</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>df<span class=\"token punctuation\">[</span><span class=\"token string\">'result'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>headers <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token string\">'User-Agent'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36 Edg/98.0.1108.56'</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> tqdm<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    res <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> headers<span class=\"token operator\">=</span>headers<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    res<span class=\"token punctuation\">.</span>encoding <span class=\"token operator\">=</span> <span class=\"token string\">'utf-8'</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    html <span class=\"token operator\">=</span> etree<span class=\"token punctuation\">.</span>HTML<span class=\"token punctuation\">(</span>res<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        item <span class=\"token operator\">=</span> html<span class=\"token punctuation\">.</span>xpath<span class=\"token punctuation\">(</span><span class=\"token string\">'//*[@id=\"prt2\"]/div'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>xpath<span class=\"token punctuation\">(</span><span class=\"token string\">'string(.)'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        result <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">,</span> re<span class=\"token punctuation\">.</span>sub<span class=\"token punctuation\">(</span><span class=\"token string\">'\\r\\n '</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">,</span> item<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    <span class=\"token keyword\">except</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        result <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    df<span class=\"token punctuation\">[</span><span class=\"token string\">'result'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> result</pre></td></tr><tr><td data-num=\"24\"></td><td><pre></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>df<span class=\"token punctuation\">.</span>to_excel<span class=\"token punctuation\">(</span><span class=\"token string\">'result.xlsx'</span><span class=\"token punctuation\">,</span> index<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>总共获取了 648 条数据.</p>\n<h6 id=\"数据预处理\"><a class=\"anchor\" href=\"#数据预处理\">#</a> 数据预处理</h6>\n<p>到这里，我们获得了 如图所示数据，但是其中仍然包含大量的 HTML 文本，同时暂时还没将原因区分</p>\n<p><img data-src=\"http://pic.ddddhm.cn/TF-IDF/image-20220226231431029.png\" alt=\"image-20220226231431029\"></p>\n<p>出来，因此，接下来需要采取正则的操作将文本规范化，同时将事故原因抽取出来。由于该网站的数据是以文档加 pdf 的形式展示的，因此在第一步先对 pdf 形式的文本进行一个去除.</p>\n<p>直接采用 pandas 中 notnull () 的方法。去除后还剩下 617 条文本.</p>\n<p>根据网站结构，我们可以知道，这里面的包含了很多结构化的信息，同时也包含了对原因的展示，在这里定义了一个函数，对网站的空字符，换行符以及 Unicode 编码进行了一个去除，接着针对标题所带的索引进行分块，然后依次遍历检索，若其中包含原因，那么该快就是对于该事故的原因解释.</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">split_function</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    type_list <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"一\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"二\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"三\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"四\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"五\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"六\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"七\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"八\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"九\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"十\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    result <span class=\"token operator\">=</span> <span class=\"token string\">\"\"</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    text <span class=\"token operator\">=</span> text<span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'\\r'</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'\\n'</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'\\t'</span><span class=\"token punctuation\">,</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>replace<span class=\"token punctuation\">(</span><span class=\"token string\">'\\u3000'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">''</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>type_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>            temptext <span class=\"token operator\">=</span> re<span class=\"token punctuation\">.</span>findall<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>type_list<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">、(.*?)</span><span class=\"token interpolation\"><span class=\"token punctuation\">&#123;</span>type_list<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">&#125;</span></span><span class=\"token string\">、\"</span></span><span class=\"token punctuation\">,</span> text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>            <span class=\"token keyword\">if</span> <span class=\"token string\">\"概况\"</span> <span class=\"token keyword\">in</span> temptext <span class=\"token keyword\">or</span> <span class=\"token string\">\"结果\"</span> <span class=\"token keyword\">in</span> temptext<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>                result <span class=\"token operator\">=</span> result <span class=\"token operator\">+</span> <span class=\"token string\">\"事故概况:\"</span> <span class=\"token operator\">+</span> temptext<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">'。'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>            <span class=\"token keyword\">if</span> <span class=\"token string\">\"原因\"</span> <span class=\"token keyword\">in</span> temptext<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>                result <span class=\"token operator\">=</span> result <span class=\"token operator\">+</span> <span class=\"token string\">\"事故原因\"</span> <span class=\"token operator\">+</span> temptext</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        <span class=\"token keyword\">except</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>            <span class=\"token keyword\">break</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token string\">\"概况\"</span> <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> result<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>            result <span class=\"token operator\">=</span> <span class=\"token string\">\"事故概况：\"</span> <span class=\"token operator\">+</span> text<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"。\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> result</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>        <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token string\">\"原因\"</span> <span class=\"token keyword\">not</span> <span class=\"token keyword\">in</span> result<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>            result <span class=\"token operator\">=</span> result <span class=\"token operator\">+</span> <span class=\"token string\">\"事故原因\"</span> <span class=\"token operator\">+</span> <span class=\"token string\">''</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"。\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    <span class=\"token keyword\">return</span> result</pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">get_reason</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre>    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre>        <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token operator\">==</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>            <span class=\"token keyword\">return</span> text<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>            <span class=\"token keyword\">return</span> text<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>    <span class=\"token keyword\">except</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>        <span class=\"token keyword\">return</span> <span class=\"token boolean\">None</span></pre></td></tr></table></figure><p><img data-src=\"http://pic.ddddhm.cn/TF-IDF/image-20220226233355724.png\" alt=\"image-20220226233355724\"></p>\n<p>这里已经成功的将原因抽取出来了.</p>\n<p>接着对筛取的结果进行进一步处理，最后将其转化为 EXCEL 存储.</p>\n<h6 id=\"分词与词典构建\"><a class=\"anchor\" href=\"#分词与词典构建\">#</a> 分词与词典构建</h6>\n<p>由于中文在处理时，首先第一步是要对其进行分词操作，同时由于新词的出现，因此需要用到行业相关的专用词典.</p>\n<p>由于 python 在分词时需要用到 txt 格式的文件作为分词，目录，所以这里需要先将.scel 格式的文件转化为 txt 格式的文件</p>\n<p>.scel 格式采用 Unicode 编码了汉字、拼音.</p>\n<p>这里直接采取别人的解析程序:</p>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\"># -*- coding: utf-8 -*-</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">import</span> struct</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">import</span> os</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token comment\"># 拼音表偏移</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>startPy <span class=\"token operator\">=</span> <span class=\"token number\">0x1540</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre> </pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># 汉语词组表偏移</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>startChinese <span class=\"token operator\">=</span> <span class=\"token number\">0x2628</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre> </pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token comment\"># 全局拼音表</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>GPy_Table <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre> </pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token comment\"># 解析结果</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token comment\"># 元组 (词频，拼音，中文词组) 的列表</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre> </pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token comment\"># 原始字节码转为字符串</span></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">byte2str</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    pos <span class=\"token operator\">=</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre>    <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> <span class=\"token string\">''</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token keyword\">while</span> pos <span class=\"token operator\">&lt;</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        c <span class=\"token operator\">=</span> <span class=\"token builtin\">chr</span><span class=\"token punctuation\">(</span>struct<span class=\"token punctuation\">.</span>unpack<span class=\"token punctuation\">(</span><span class=\"token string\">'H'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">bytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">[</span>pos <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        <span class=\"token keyword\">if</span> c <span class=\"token operator\">!=</span> <span class=\"token builtin\">chr</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre>            <span class=\"token builtin\">str</span> <span class=\"token operator\">+=</span> c</pre></td></tr><tr><td data-num=\"24\"></td><td><pre>        pos <span class=\"token operator\">+=</span> <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    <span class=\"token keyword\">return</span> <span class=\"token builtin\">str</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre> </pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token comment\"># 获取拼音表</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">getPyTable</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    data <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre>    pos <span class=\"token operator\">=</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre>    <span class=\"token keyword\">while</span> pos <span class=\"token operator\">&lt;</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre>        index <span class=\"token operator\">=</span> struct<span class=\"token punctuation\">.</span>unpack<span class=\"token punctuation\">(</span><span class=\"token string\">'H'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">bytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>data<span class=\"token punctuation\">[</span>pos <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"33\"></td><td><pre>        pos <span class=\"token operator\">+=</span> <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre>        lenPy <span class=\"token operator\">=</span> struct<span class=\"token punctuation\">.</span>unpack<span class=\"token punctuation\">(</span><span class=\"token string\">'H'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">bytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">[</span>pos <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"35\"></td><td><pre>        pos <span class=\"token operator\">+=</span> <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        py <span class=\"token operator\">=</span> byte2str<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">:</span>pos <span class=\"token operator\">+</span> lenPy<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> </pre></td></tr><tr><td data-num=\"37\"></td><td><pre>        GPy_Table<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> py</pre></td></tr><tr><td data-num=\"38\"></td><td><pre>        pos <span class=\"token operator\">+=</span> lenPy</pre></td></tr><tr><td data-num=\"39\"></td><td><pre>        </pre></td></tr><tr><td data-num=\"40\"></td><td><pre><span class=\"token comment\"># 获取一个词组的拼音</span></pre></td></tr><tr><td data-num=\"41\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">getWordPy</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre>    pos <span class=\"token operator\">=</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"43\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token string\">''</span></pre></td></tr><tr><td data-num=\"44\"></td><td><pre>    <span class=\"token keyword\">while</span> pos <span class=\"token operator\">&lt;</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"45\"></td><td><pre>        index <span class=\"token operator\">=</span> struct<span class=\"token punctuation\">.</span>unpack<span class=\"token punctuation\">(</span><span class=\"token string\">'H'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">bytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">[</span>pos <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"46\"></td><td><pre>        ret <span class=\"token operator\">+=</span> GPy_Table<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"47\"></td><td><pre>        pos <span class=\"token operator\">+=</span> <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"48\"></td><td><pre>    <span class=\"token keyword\">return</span> ret</pre></td></tr><tr><td data-num=\"49\"></td><td><pre> </pre></td></tr><tr><td data-num=\"50\"></td><td><pre><span class=\"token comment\"># 读取中文表</span></pre></td></tr><tr><td data-num=\"51\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">getChinese</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"52\"></td><td><pre>    GTable <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"53\"></td><td><pre>    pos <span class=\"token operator\">=</span> <span class=\"token number\">0</span></pre></td></tr><tr><td data-num=\"54\"></td><td><pre>    <span class=\"token keyword\">while</span> pos <span class=\"token operator\">&lt;</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"55\"></td><td><pre>        <span class=\"token comment\"># 同音词数量</span></pre></td></tr><tr><td data-num=\"56\"></td><td><pre>        same <span class=\"token operator\">=</span> struct<span class=\"token punctuation\">.</span>unpack<span class=\"token punctuation\">(</span><span class=\"token string\">'H'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">bytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">[</span>pos <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"57\"></td><td><pre>        <span class=\"token comment\"># 拼音索引表长度</span></pre></td></tr><tr><td data-num=\"58\"></td><td><pre>        pos <span class=\"token operator\">+=</span> <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"59\"></td><td><pre>        py_table_len <span class=\"token operator\">=</span> struct<span class=\"token punctuation\">.</span>unpack<span class=\"token punctuation\">(</span><span class=\"token string\">'H'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">bytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">[</span>pos <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"60\"></td><td><pre>        <span class=\"token comment\"># 拼音索引表</span></pre></td></tr><tr><td data-num=\"61\"></td><td><pre>        pos <span class=\"token operator\">+=</span> <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"62\"></td><td><pre>        py <span class=\"token operator\">=</span> getWordPy<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">:</span> pos <span class=\"token operator\">+</span> py_table_len<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"63\"></td><td><pre>        <span class=\"token comment\"># 中文词组</span></pre></td></tr><tr><td data-num=\"64\"></td><td><pre>        pos <span class=\"token operator\">+=</span> py_table_len</pre></td></tr><tr><td data-num=\"65\"></td><td><pre>        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>same<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"66\"></td><td><pre>            <span class=\"token comment\"># 中文词组长度</span></pre></td></tr><tr><td data-num=\"67\"></td><td><pre>            c_len <span class=\"token operator\">=</span> struct<span class=\"token punctuation\">.</span>unpack<span class=\"token punctuation\">(</span><span class=\"token string\">'H'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">bytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">[</span>pos <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"68\"></td><td><pre>            <span class=\"token comment\"># 中文词组</span></pre></td></tr><tr><td data-num=\"69\"></td><td><pre>            pos <span class=\"token operator\">+=</span> <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"70\"></td><td><pre>            word <span class=\"token operator\">=</span> byte2str<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">:</span> pos <span class=\"token operator\">+</span> c_len<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"71\"></td><td><pre>            <span class=\"token comment\"># 扩展数据长度</span></pre></td></tr><tr><td data-num=\"72\"></td><td><pre>            pos <span class=\"token operator\">+=</span> c_len</pre></td></tr><tr><td data-num=\"73\"></td><td><pre>            ext_len <span class=\"token operator\">=</span> struct<span class=\"token punctuation\">.</span>unpack<span class=\"token punctuation\">(</span><span class=\"token string\">'H'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">bytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">[</span>pos <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"74\"></td><td><pre>            <span class=\"token comment\"># 词频</span></pre></td></tr><tr><td data-num=\"75\"></td><td><pre>            pos <span class=\"token operator\">+=</span> <span class=\"token number\">2</span></pre></td></tr><tr><td data-num=\"76\"></td><td><pre>            count <span class=\"token operator\">=</span> struct<span class=\"token punctuation\">.</span>unpack<span class=\"token punctuation\">(</span><span class=\"token string\">'H'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">bytes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">[</span>pos<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">[</span>pos <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"77\"></td><td><pre>            <span class=\"token comment\"># 保存</span></pre></td></tr><tr><td data-num=\"78\"></td><td><pre>            GTable<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>count<span class=\"token punctuation\">,</span> py<span class=\"token punctuation\">,</span> word<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"79\"></td><td><pre>            <span class=\"token comment\"># 到下个词的偏移位置</span></pre></td></tr><tr><td data-num=\"80\"></td><td><pre>            pos <span class=\"token operator\">+=</span> ext_len</pre></td></tr><tr><td data-num=\"81\"></td><td><pre>    <span class=\"token keyword\">return</span> GTable</pre></td></tr><tr><td data-num=\"82\"></td><td><pre> </pre></td></tr><tr><td data-num=\"83\"></td><td><pre><span class=\"token keyword\">def</span> <span class=\"token function\">scel2txt</span><span class=\"token punctuation\">(</span>file_name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"84\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'-'</span> <span class=\"token operator\">*</span> <span class=\"token number\">60</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"85\"></td><td><pre>    <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_name<span class=\"token punctuation\">,</span> <span class=\"token string\">'rb'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"86\"></td><td><pre>        data <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"87\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"词库名：\"</span><span class=\"token punctuation\">,</span> byte2str<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0x130</span><span class=\"token punctuation\">:</span><span class=\"token number\">0x338</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># .encode('GB18030')</span></pre></td></tr><tr><td data-num=\"88\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"词库类型：\"</span><span class=\"token punctuation\">,</span> byte2str<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0x338</span><span class=\"token punctuation\">:</span><span class=\"token number\">0x540</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"89\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"描述信息：\"</span><span class=\"token punctuation\">,</span> byte2str<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0x540</span><span class=\"token punctuation\">:</span><span class=\"token number\">0xd40</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"90\"></td><td><pre>    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"词库示例：\"</span><span class=\"token punctuation\">,</span> byte2str<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token number\">0xd40</span><span class=\"token punctuation\">:</span>startPy<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"91\"></td><td><pre>    getPyTable<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span>startPy<span class=\"token punctuation\">:</span>startChinese<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"92\"></td><td><pre>    getChinese<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span>startChinese<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"93\"></td><td><pre>    <span class=\"token keyword\">return</span> getChinese<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span>startChinese<span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"94\"></td><td><pre></pre></td></tr><tr><td data-num=\"95\"></td><td><pre><span class=\"token comment\"># scel 所在文件夹路径</span></pre></td></tr><tr><td data-num=\"96\"></td><td><pre>in_path <span class=\"token operator\">=</span> <span class=\"token string\">'./专业词词库'</span></pre></td></tr><tr><td data-num=\"97\"></td><td><pre><span class=\"token comment\"># 输出词典所在文件夹路径</span></pre></td></tr><tr><td data-num=\"98\"></td><td><pre>out_path <span class=\"token operator\">=</span> <span class=\"token string\">'./词库'</span></pre></td></tr><tr><td data-num=\"99\"></td><td><pre>fin <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>fname <span class=\"token keyword\">for</span> fname <span class=\"token keyword\">in</span> os<span class=\"token punctuation\">.</span>listdir<span class=\"token punctuation\">(</span>in_path<span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> fname<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">5</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token string\">\".scel\"</span><span class=\"token punctuation\">]</span></pre></td></tr><tr><td data-num=\"100\"></td><td><pre><span class=\"token keyword\">for</span> f <span class=\"token keyword\">in</span> fin<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"101\"></td><td><pre>    <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"102\"></td><td><pre>        <span class=\"token keyword\">for</span> word <span class=\"token keyword\">in</span> scel2txt<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>in_path<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"103\"></td><td><pre>            file_path<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>out_path<span class=\"token punctuation\">,</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>f<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">'.'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token string\">'.txt'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"104\"></td><td><pre>            <span class=\"token comment\"># 保存结果</span></pre></td></tr><tr><td data-num=\"105\"></td><td><pre>            <span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_path<span class=\"token punctuation\">,</span><span class=\"token string\">'a+'</span><span class=\"token punctuation\">,</span>encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span><span class=\"token keyword\">as</span> <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"106\"></td><td><pre>                <span class=\"token builtin\">file</span><span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token string\">'\\n'</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"107\"></td><td><pre>        os<span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>in_path<span class=\"token punctuation\">,</span> f<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"108\"></td><td><pre>    <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span></pre></td></tr><tr><td data-num=\"109\"></td><td><pre>        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"110\"></td><td><pre>        <span class=\"token keyword\">pass</span></pre></td></tr></table></figure><p>接着在对上述生成的 txt 文本进行一个合并操作，最终生成了一个自定义词典.</p>\n<p>然后采用 jieba 分词，将其转化为词的形式.</p>\n<h6 id=\"数据集处理\"><a class=\"anchor\" href=\"#数据集处理\">#</a> 数据集处理</h6>\n<p>采取上述爬取的数据集和人工收集到的第二份数据集进行合并，由于分析对象选取的是 2007 年以后，所以针对其进行了进一步的筛选操作。还剩余 425 条数据.</p>\n<h6 id=\"模型导入\"><a class=\"anchor\" href=\"#模型导入\">#</a> 模型导入</h6>\n<figure class=\"highlight python\"><figcaption data-lang=\"python\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">#TfidfVectorizer 为上述 CountVectorizer,TfidfTransformer 的集合</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>vector <span class=\"token operator\">=</span> TfidfVectorizer<span class=\"token punctuation\">(</span>stop_words<span class=\"token operator\">=</span>stoplist<span class=\"token punctuation\">,</span> vocabulary <span class=\"token operator\">=</span> vocab<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>tf_idf <span class=\"token operator\">=</span> vector<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>corpus<span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>由于文章包含大量描述性的话语，同时存在多个词语指代同一词语的现象，因此，在此基础上，对停用词词典进行进一步调整，然后根据 top50 的词频，将其跟原因相关的词汇进行分类，将原因分为如下四类:</p>\n<ul>\n<li>安全因素:' 安全生产 ',' 安全管理 ',' 安全隐患 ',' 培训 ',' 安全生产工作 ',' 现场安全管理 ',' 教育'</li>\n<li>管理因素:' 管理 ',' 监理 ',' 组织 ',' 落实 ',' 履行 ',' 监督 ',' 协调 ',' 混乱 ',' 监督管理 ',' 审批'</li>\n<li>工作因素:' 检查 ',' 排查 ',' 违反 ',' 整改 ', ' 拆除 ',' 调查 ',' 发现 ',' 验收'</li>\n<li>其他因素 ' 隐患 ',' 分包 ',' 救援 ',' 临时'</li>\n</ul>\n<p>同时将其词频分布以词云图的形式展现。</p>\n<p><img data-src=\"http://pic.ddddhm.cn/TF-IDF/image-20220227153628664.png\" alt=\"image-20220227153628664\"></p>\n<p><img data-src=\"http://pic.ddddhm.cn/TF-IDF/image-20220227161321175.png\" alt=\"image-20220227161321175\"></p>\n<p>最后将其结果以上述关键词进行一个分类。</p>\n",
            "tags": []
        }
    ]
}